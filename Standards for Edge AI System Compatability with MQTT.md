# Standards for Edge AI System Compatability with MQTT
Version 2023.11.15_Pre-Draft

## Introduction
MQTT is one of the most popular protocols for connecting IIoT devices and unifying distributed data sources. Using MQTT makes it possible to run centralized analytics in the cloud by subscribing to, processing, and analyzing data across a wide range of devices and sensors. However, with machine learning and AI reaching the edge, predictions and insights are being generated in real-time outside of the cloud. Currently, there are no well-defined standards for how predictions and insights generated by AI models from data sources such as camera feeds, acoustic sensors, and other unstructured data sources should be integrated into MQTT-backed environments. This standard seeks to provide a reuseable yet flexible way to integrate edge AI into both Flat and Sparkplug B MQTT specifications.

## Common Patterns for Edge AI on MQTT
Edge AI applications are wildly diverse and often need to incorporate high performance hardware, specialized sensors, and sophisticated ML models to process data sources such as video, audio, or raw machine data. However, for the sake of considering how edge AI and MQTT can work together, we can breakdown all of these applications into one of four patterns as shown in the table below.

Table A: Edge AI on MQTT Design Patterns
|                                                    | Model Output: MQTT Publish      | Model Output: Other non MQTT-compliant system |
|----------------------------------------------------|---------------------------------|-----------------------------------------------|
| **Model Input: MQTT Subscribe**                    | The "Fully-integrated" pattern  | The "Ambassador" pattern                      |
| **Model Input: Other non MQTT-compliant systems.** | The "Unstructured Data" pattern | _Not covered by this standard_                |

### The "Fully-integrated" pattern
This pattern represents an AI/ML system where both data inputs and predicted outputs are all being published and consumed over MQTT. This pattern is best suited for AI & ML applications running on structured data (tabular or machine data) that is already being published to MQTT. Models consuming data in this pattern may include applications like predictive maintenance, as part of a feedback control system, or for general time-series classification.

One of the most important aspects to consider for the Fully-integrated pattern is the data format of incoming data being processed by a model. Typically, machine learning models have strict data format requirements and can only process data that adheres to that format. These formats typically take the shape of either tables, tensors, or other arrays. Machine learning models can provide some amount of pre-processing, but building in sophisticated data formatting into a model is not efficient. Instead of building sophisticated data handling into models running at the edge, it's best to ensure that payloads for any topics that a model must subscribe to are using the same format. This can be done at the device level by formatting data to meet that standard or, better yet, by introducing a data transformation layer that can provide common formatting before republishing that data to a new topic.

### The "Unstructured Data" pattern
This pattern represents an AI/ML system where input data is available via some other system or protocol, then that raw data is processed through a model, and finally predictions are published to MQTT.

AI/ML systems operating in this pattern present some of the most ideal applications for using AI at the edge. Unstructured data sources such as images, full motion video, audio, and lidar are not well suited to being transmitted over MQTT. First of all, they are increadibly large, heavy data sources. Secondly, many of them are continuous, meaning they do not align well with an event-based architecture. Through the use of AI/ML models, this raw data can be converted into insights such as detections of specific objects, vehicles, or people that are of interest, and then those insights can be published back to MQTT using very little bandwidth.

### The "Ambassador" pattern
This pattern represents an AI/ML system where input data is published to MQTT and processed by one or more AI & ML models, but is then sent to another system via a different protocol.

AI/ML systems operating in this pattern may include applications such as robotics, where sensor data is used to generate a prediction and then fed directly to a control system.

## Standards for Topic Definition
One of the most important parts of setting up any MQTT system is designing a firm yet flexible topic structure. There are many ways to define such a structure including the ISA-95 standard or Sparkplug B. The standards provided in this document can work in conjunction with either of these standards, or with custom-defined topic structures. The focus in this document is to establish recommendations for logical naming conventions that seemlessly integrate machine learning into live MQTT systems.

### Namespace  Definition
A key step to topic namespace structuring would be the identification of Edge AI namespaces. We propose two namespaces to begin with: Raw Data Namespace and Functional Namespace. The namespaces can be renamed according to AI nomenclature.

#### Raw Data Namespace
The primary objective of the Raw Data Namespace is to hold, in the Unified Namespace, raw data as it appears directly from sensors. Typically this would include sensors that are generated "structured" data such as tables, log lines, or tensors. This namespace would not _typically_ be used with cameras or audio sensors as MQTT is not an ideal way to share unstructured data.

#### Functional Namespace
The primary objectives of the Functional Namespace are:
* Designing and structuring ML result data types.
* Implementing consistent naming conventions.
* Normalizing units of measurement.
* Mapping data to appropriate user-defined types (UDTs).
* Ensuring data compatibility and readiness for integration with other applications.

Here we propose two foundational functional namespace categories that could be utilized within an AI/ML-powered context.
* "inference": This category of topics would refer to metrics directly generated by a machine learning model. These outputs are very transactional and do not necessarily provide business value on their own. In the context of computer vision, messages published to an "inference" metric might count the number of people and hardhats detected within a video frame.
* "insight": This category of topics would refer to metrics with innate business value that are composed, calculated, or otherwise built on top of individual inference metrics. Using the computer vision example from above, an "insight" metric might subtract the number of hardhats from the number of people in a video frame to determine if someone is not wearing protective equipment.

### Flat MQTT Topic Namespace Structuring

#### Raw Data Namespace

_(**Note to standards reviewers:** This diagram is illustrative, but as an early draft, may be out of date with the current text found within this standard)_

![](diagrams/raw_data_namespace-in_flat_MQTT.png)

#### Functional Namespace

_(**Note to standards reviewers:** This diagram is illustrative, but as an early draft, may be out of date with the current text found within this standard)_

![](diagrams/functional_namespace_in_flat_MQTT.png)

### MQTT Sparkplug Topic Namespace Structuring

#### Raw Data Namespace

_(**Note to standards reviewers:** This diagram is illustrative, but as an early draft, may be out of date with the current text found within this standard)_

![](diagrams/sparkplug_topic_namespace_structuring_raw.png)

#### Functional Namespace

_(**Note to standards reviewers:** This diagram is illustrative, but as an early draft, may be out of date with the current text found within this standard)_

![](diagrams/sparkplug_topic_namespace_structuring_functional.png)

### UNS Snapshot
Within the context of a unified namespace, raw and functional topics would coexist as follows.

Site

└ Area

&nbsp; └ Line

&nbsp; &nbsp; └ Cell

&nbsp; &nbsp; &nbsp; └ Node

&nbsp; &nbsp; &nbsp; &nbsp; └ Device

&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; └ “raw/sensor_name” -> This raw value from a sensor is in the "Raw Data" namespace and is consumed by a model

&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; └ “inference/model_id/version” -> This funtional value is a predicted value from a specific model and version

&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; └ "insight/business_metric" -> This functional value is the business metric that is composed of raw data processed through one or more models, and then refined to create a meaningful insight out of this data.

#### Examples
**"Fully-Integrated" Example**

Machine learning-powered predictive maintenance
* Raw data topic: `site/area/line/cell/node/device/raw`
    * Metrics published each second, including: Air temperature (K), Process temperature (K), Rotational speed (rpm), Torque (Nm), Tool wear (min)
* Functional "inference" topic: `site/area/line/cell/node/device/inference/brzrip6cxk/0.0.1`
    * Metrics published each second: `failure` and `no_failure` classifications along with corresponding scores.
* Functional "insight" topic: `site/area/line/cell/node/device/insight/maintenance_required`
    * Metric published each minute: Boolean of whether maintenance is required based whether or not the `failure` score is larger than the `no_failure` score

## Standards for Payload Definition
Machine learning applications at the edge are primarily focused on providing two types of outputs (1) predictions about things the _may_ happen in the future and (2) insights translated from unstructured sources (audio, video, etc.) into structured insights (classification or detection). Downstream systems require detailed information in order to make use of these outputs. Establishing structured formats for these model outputs makes systems more interoperable.

### Formatting MQTT payloads
When publishing data to an MQTT broker, there are a number of ways of encoding the information. The three most common types include XML, JSON, and Protobuf.

#### Protobuf
Protobuf is the highest performing format and should be the top choice in payload format when developing new AI & ML powered systems. Because data in the protobuf format is sent as bytes, not raw text, message sizes are much smaller when using protobuf as compared to XML or JSON. Additionally, `.proto` files enforce a common understanding of message formats, so schema changes resulting in downstream errors are not an issue. Protobuf is also used by Sparkplug, so it provides the most future-proof format.

#### JSON
JSON can also be a good choice for formatting payload data. First of all, JSON objects are human readable, which makes them easier to debug when developing new connected systems, compared to protbuf where the messages themselves are sent as bytes. Secondly, since JSON is ubiquitous, most systems can read, write, or interpret JSON. This makes it well suited for compatibility across multiple systems. Its primary downsides include the fact that message sizes are larger than protobuf, and there is no real mechanism to enforce a strict data structure. This results in scenarios where if an upstream system publishes a change to a JSON schema, downstream systems may experience errors until they have been updated to parse this change.

#### XML
XML has some value for legacy systems and may be a necessary choice, but it should be the last option in most situations. JSON provides similar levels of human readabillity to XML while protobuf offers a significantly smaller message size. Aside from legacy compatibility, it should generally be avoided.

#### Formatting recommendation
It is recommended to default to a protobuf format for AI & ML model output messages when at all possible. In the event that protobuf does not support a certain integration, JSON is the next best option. This standard provides examples in both protobuf and JSON, but not XML.

### Flat MQTT model payload
For Flat MQTT applications, we propose the following general payload object. This object format can be used with any type of models by providing flexibility within the `results` object to provide support for both pre-defined model formats as well as custom formats. The `results` object could then be customized to contain the model-specific data struture. In a JSON format, this model data structure would appear as follows.

```json
{
   "identifier":"inference-2HYZh8a4jtFi3xFc4e3TWRmclff",
   "model":{
      "identifier":"brzrip6cxk",
      "version":"0.0.1",
      "name":"Machine Failure Prediction"
   },
   "tags":{
      "srcTopic":"site:area:line:cell/node/device/raw/sensor_name",
      "messageID":"abcd1234",
      "inputSizeInBytes":32,
      "inputSha256Digest":"be01ef104fb88fd151132733e746fe29b997348bf34be875e25ba48c0d7436ca"
   },
   "results":[
      {
         "classPredictions":[
            {
               "className":"no_failure",
               "score":0.974
            },
            {
               "className":"failure",
               "score":0.026
            }
         ],
         "modelType":"classPredictions",
         "dataType":"String"
      }
   ],
   "explaination":{
      
   }
}

```
Below is a breakdown of the key components found within this payload format:
* `identifier`: This represents a unique ID for an individual inference which might be useful or necessary for historical review or fo mapping model predictions to a given piece of input data
* `model`: This object provides important metadata about the model used to generate this output (*note to standards contributors* `identifier` and `version` will already be captured in the topic, so these values are redundant and could likely be removed)
* `tags`: Tags provide a way to incorporate metadata related to the input fed into the model that generated an inference, including the topic that it came from, as well as a hash of the incoming data itself
* `results`: The object containing a model's outputs (i.e. predictions or inferences). Results can be provided as one of three types:
    * `textValue`: This type would exclusively be used to return raw text results
    * `jsonValue`: This type would be used to return a JSON object in raw text
    * `base64EncodedValue`: This type would be used to return a JSON object in a base64 encoded format
* `explanation`: This field provides space to incorporate explainable outputs directly from the model itself. Explainable outputs are typically used to provide insight into how a machine learning model came to it's prediction

### Sparkplug MQTT model payloads

#### DBIRTH
DBIRTH messages for edge AI applications will need to inform Host Applications about all AI and ML metrics that it will be published by this edge device in the future. If new models are added to an edge device, a new DBIRTH message would need to be published.

**DBIRTH Topic**
Example topic:

```
spBv1.0/Site:Area:Line:Cell/DBIRTH/Edge Node ID/Edge Device ID
```

**DBIRTH Payload**

Example payload for classification model:
```
{
   "timestamp":1486144502122,
   "metrics":[
      {
         "name":"inference/identifier",
         "timestamp":1486144502122,
         "dataType":"string",
         "value":"inference-2HYZh8a4jtFi3xFc4e3TWRmclff"
      },
      {
         "name":"inference/model/identifier",
         "timestamp":1486144502122,
         "dataType":"string",
         "value":"brzrip6cxk"
      },
      {
         "name":"inference/model/version",
         "timestamp":1486144502122,
         "dataType":"string",
         "value":"0.0.1"
      },
      {
         "name":"inference/model/name",
         "timestamp":1486144502122,
         "dataType":"string",
         "value":"Machine Failure Prediction"
      },
      {
         "name":"inference/tags/sourceTopic",
         "timestamp":1486144502122,
         "dataType":"string",
         "value":"site:area:line:cell/node/device/raw/sensor_name"
      },
      {
         "name":"inference/tags/messageID",
         "timestamp":1486144502122,
         "dataType":"string",
         "value":"abcd1234"
      },
      {
         "name":"inference/tags/inputSizeInBytes",
         "timestamp":1486144502122,
         "dataType":"integer",
         "value":32
      },
      {
         "name":"inference/tags/inputSha256Digest",
         "timestamp":1486144502122,
         "dataType":"string",
         "value":"be01ef104fb88fd151132733e746fe29b997348bf34be875e25ba48c0d7436ca"
      },
      {
         "name":"inference/results/classPredictions",
         "timestamp":1486144502122,
         "dataType":"string",
         "value":'[{"className":"no_failure","score":0.974},{"className":"failure","score":0.026}]'
      },
      {
         "name":"inference/results/modelType",
         "timestamp":1486144502122,
         "dataType":"string",
         "value":"classPredictions"
      },
      {
         "name":"inference/results/dataType",
         "timestamp":1486144502122,
         "dataType":"string",
         "value":"String"
      }
   ],
   "seq":1
}
```

This would result in a structure as follows on the Host Application.

| Metric                                         |               | Value                                                                            | Data Type |
| ---------------------------------------------- | ------------- | -------------------------------------------------------------------------------- | --------- |
| Site:Area:Line:Cell                            | /group_id     |                                                                                  |           |
| └Edge Node ID                                  | /edge_node_id |                                                                                  |           |
| &nbsp; └Edge Device ID                         | /device_id    |                                                                                  |           |
| &nbsp; &nbsp; └Inference                       |               |                                                                                  |           |
| &nbsp; &nbsp; &nbsp; └identifier               |               | inference-2HYZh8a4jtFi3xFc4e3TWRmclff                                            | String    |
| &nbsp; &nbsp; &nbsp; └model                    |               |                                                                                  |           |
| &nbsp; &nbsp; &nbsp; &nbsp; └identifier        |               | brzrip6cxk                                                                       | String    |
| &nbsp; &nbsp; &nbsp; &nbsp; └version           |               | 0.0.1                                                                            | String    |
| &nbsp; &nbsp; &nbsp; &nbsp; └name              |               | Machine Failure Prediction                                                       | String    |
| &nbsp; &nbsp; &nbsp; └tags                     |               |                                                                                  |           |
| &nbsp; &nbsp; &nbsp; &nbsp; └sourceTopic       |               | site:area:line:cell/node/device/raw/sensor_name                                  | String    |
| &nbsp; &nbsp; &nbsp; &nbsp; └dataType          |               | abcd1234                                                                         | String    |
| &nbsp; &nbsp; &nbsp; &nbsp; └inputSizeInBytes  |               | 32                                                                               | Integer   |
| &nbsp; &nbsp; &nbsp; &nbsp; └inputSha256Digest |               | be01ef104fb88fd1...                                                              | String    |
| &nbsp; &nbsp; &nbsp; └results                  |               |                                                                                  |           |
| &nbsp; &nbsp; &nbsp; &nbsp; └classPredictions  |               | [{"className":"no_failure","score":0.974},{"className":"failure","score":0.026}] | String    |
| &nbsp; &nbsp; &nbsp; &nbsp; └modelType         |               | classPredictions                                                                 | String    |
| &nbsp; &nbsp; &nbsp; &nbsp; └dataType          |               | string                                                                           | String    |

*(note: What if a model uses more than one source topic? Should one pass along an array, or create multiple numbered "sourceTopic" values: sourceTopic1, sourcTopic2, etc.)

#### DDATA

**DBIRTH Topic**
Example topic:
```
spBv1.0/Site:Area:Line:Cell/DDATA/Edge Node ID/Edge Device ID
```



### AI/ML model result formats
Below are recommended JSON structures for the most common types of machine learning models. Protofile definitions of these data formats are also available in the appendix and on Github.

#### Classification
Classification is used to assign a class to an individual piece of data. This might be useful for classifying an individual image, audio snippet, video frame, or a piece of machine data.
```json
{
   "classPredictions":[
      {
         "class":"className",
         "score":1.0
      }
   ]
}
```
#### Time series classification
Time series classification is used to classify a temporal range within a larger time series data set. This might be useful for classifying audio, video, or sensor data.
```json
{
   "timeSeriesPredictions":[
      {
         "class":"className",
         "score":1.0,
         "start":"2020-01-06 00:00:00.000000",
         "end":"2020-01-06 00:00:59.000000"
      }
   ]
}
```

#### Multi-classification
Similar to classification models, but used when model outputs are grouped into more than two distinct classes.
```json
{
   "classifications":[
      {
         "classPredictions":[
            {
               "class":"className",
               "score":1.0
            }
         ]
      }
   ]
}
```

#### Object detection
Object detection is used to identify regions of interest within an image or video that are defined by a bounding box. Bounding boxes can have one or more classifications, and images can have one or more bounding boxes.
```json
{
   "detections":[
      {
         "class":"className",
         "score":1.0,
         "boundingBox":{
            "x":100,
            "y":200,
            "width":300,
            "height":400
         }
      }
   ]
}
```

#### Image segmentation
Image segmentation is used to highlight specific pixesl within an image or a video frame that are of importance. There are three primary ways to communicate which portions of an image are of importance: run-lenth encoding (RLE), point specification, and raw image outputs.

##### Run-length encoding format
```json
{
   "segments":[
      {
         "class":"className",
         "score":1.0,
         "imageMask":{
            "originalWidth":500,
            "originalHeight":600,
            "rle":[1,0,1,0,0,0,1,1]
         },
         "boundingBox":{
            "x":100,
            "y":200,
            "width":300,
            "height":400
         }
      }
   ]
}
```
##### Image format

##### Points format
```json
{
   "segments":[
      {
         "class":"className",
         "score":1.0,
         "imageMask":{
            "originalWidth":500,
            "originalHeight":600,
            "points":[
               {
                  "x":1,
                  "y":0
               },
               {
                  "x":1,
                  "y":1
               },
               {
                  "x":2,
                  "y":0
               },
               {
                  "x":2,
                  "y":1
               }
            ]
         },
         "boundingBox":{
            "x":100,
            "y":200,
            "width":300,
            "height":400
         }
      }
   ]
}
```

#### Named entity recognition
Named entity recognition is used to identify unique entities, such as names, organizations, and locations, within a larger corpus of text.
```json
{
   "entities":[
      {
         "entityGroup":"B-LOC",
         "score":1.0,
         "textSpan":{
            "start":0,
            "end":5,
            "text":"Paris is a city."
         }
      }
   ]
}
```

#### Text summarization
Text summarization is used to 
```json
{
    "text":"Summarized text"
}
```

#### Text generation
```json
{
    "text":"Generated text"
}
```

#### Translation
```json
{
    "text":"Translated text"
}
```
#### Audio segmentation
#### Regression
#### Ranking

## Contributors
Kudzai Manditereza, HiveMQ
Seth Clark, Modzy
Nathan Mellis, Modzy
Bradly Munday, Modzy
Brent Wassell, Oshkosh
Joshua Coenen, Oshkosh

## Appendix A: ML Message Definitions
### Results

```proto
syntax = "proto3";
package chassis.v2;

import "chassis/v2/types.proto";
import "google/api/field_behavior.proto";

message ClassificationResult {
message Prediction {
string class = 1 [(google.api.field_behavior) = REQUIRED];
double score = 2 [(google.api.field_behavior) = REQUIRED];
}
repeated Prediction class_predictions = 1;
}
message MultiClassificationResult {
repeated ClassificationResult classifications = 1;
}

message ObjectDetectionResult {
message Detection {
string class = 1 [(google.api.field_behavior) = REQUIRED];
double score = 2 [(google.api.field_behavior) = REQUIRED];
BoundingBox bounding_box = 3 [(google.api.field_behavior) = REQUIRED];
}
repeated Detection detections = 1;
}

// Segmentation
message SegmentationResult {
message Segment {
string class = 1 [(google.api.field_behavior) = REQUIRED];
double score = 2 [(google.api.field_behavior) = REQUIRED];
ImageMask image_mask = 3;
BoundingBox bounding_box = 4;
}
repeated Segment segments = 1;
}

message NamedEntityResult {
message NamedEntity {
string entity_group = 1 [(google.api.field_behavior) = REQUIRED];
double score = 2 [(google.api.field_behavior) = REQUIRED];
TextSpan text_span = 3;
}
repeated NamedEntity entities = 1;
}

// Text summarization
// Text generation
// Translation
message TextResult {
string text = 1;
}

// Image/video
message ImageResult {
repeated bytes data = 1;
}

// Audio segmentation
// Time-series classification
// Regression
// Ranking
```

## Explanations

```proto
syntax = "proto3";
package chassis.v2;

import "chassis/v2/types.proto";

message ImageExplanation {
ImageMask mask = 1;
}

message TextExplanation {
message TextSpanScore {
TextSpan text_span = 1;
double score = 2;
}
message ClassResults {
string class = 1;
repeated TextSpanScore scores = 2;
}
repeated ClassResults class_results = 1;
}

// Saliency maps
// SHAP
// Lime's tabular
// Lime text classification
// Object detection
```

## Appendix B: Example Implementations
