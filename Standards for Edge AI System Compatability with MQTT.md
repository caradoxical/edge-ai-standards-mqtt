# Standards for Edge AI System Compatability with MQTT
Version 2023.11.15_Pre-Draft

## Introduction
MQTT is one of the most popular protocols for connecting IIoT devices and unifying distributed data sources. Using MQTT to implement a Unified Namespace (UNS) makes it easy to run centralized analytics in the cloud. However, AI technologies have now reached the industrial edge, meaning that predictions and insights are being generated in real-time outside of the cloud. Currently, there are no well-defined standards for how predictions and insights generated by AI models from data sources like camera feeds, acoustic sensors, and other unstructured data sources should be integrated into a Sparkplug-compliant UNS. This standard seeks to provide a repeatable and resilient way to integrate edge AI into MQTT Sparkplug systems.

## Challenges with adopting the MQTT Sparkplug for edge AI
Topic definitions do not easily map onto AI terminology
How should one name SparkPlug B-compliant topics for machine learning models operating at the edge? What if a single device is running multiple AI models?

AI predictions often container a great deal of metadata and heirarchical information
How should predictive insights be formatted to adhere to the SparkPlug B message format?

Edge environments are often exposed to significant amounts of unstructured data not well suited for MQTT

## Architectures for Edge AI

## Standards for Topic Definition
### Subscribing Standards
ML models developed by data scientists are often developed by separate data science teams not directly involved in the nuances of UNS systems developed for operational environments. As a result, the models they build are designed expected a strictly adopted data format for their models to generate meaningful results. As a result, it’s important that data science teams that develop AI models and operational teams responsible for implementing AI models into realtime MQTT systems understand how data needs to be structured for a model to operated correctly.
Expectation: MQTT messages ingested by ML models ought to be formatted exactly in the way that a ML model expects inputs to be formatted. This makes it possible for models to be updated and improved overtime without pipelines breaking down as a result of these changes.

### Publishing Standards
Key pieces of information needed to data scientists for model evaluation and lifecycle management:
 * Model name
 * Unique model identifier
 * Model version (semver recommended)

## Standards for Payload Definition
One simple option for adding ML outputs to an Sparkplug payload would be to use the string data type and just add model predictions and outputs in the form of raw json. This brute force option can certainly work in a pinch, but loses all of the benefits of Sparkplug’s structure, making it harder to scale different types of models across large MQTT deployments without a great deal of institutional knowledge needed to interpret results. A better approach would be to adopt the structure defined
Note: Templates may be the right solution for custom ML result data types such as classifications, segmentations, etc.
Explainability and drift (calculated locally by the model) could extend the top-level payload definitions?

### Model format-specific payloads
#### Tensor
For tensors, it might be best to use the Sparkplug dataset definition
#### Classification
#### Recommended format for classification model outputs
#### Multi-classification
#### Object detection
#### Image segmentation
#### Named entity recognition
#### Text summarization
#### Text generation
#### Translation
#### Image
#### Video
#### Audio segmentation
#### Time-series classification
#### Regression
#### Ranking

## Contributors
Kudzai Manditereza, HiveMQ
Seth Clark, Modzy
Nathan Mellis, Modzy
Bradly Munday, Modzy
Brent Wassell, Oshkosh
Joshua Coenen, Oshkosh

## Appendix A: ML Message Definitions
### Results

```proto
syntax = "proto3";
package chassis.v2;

import "chassis/v2/types.proto";
import "google/api/field_behavior.proto";

message ClassificationResult {
message Prediction {
string class = 1 [(google.api.field_behavior) = REQUIRED];
double score = 2 [(google.api.field_behavior) = REQUIRED];
}
repeated Prediction class_predictions = 1;
}
message MultiClassificationResult {
repeated ClassificationResult classifications = 1;
}

message ObjectDetectionResult {
message Detection {
string class = 1 [(google.api.field_behavior) = REQUIRED];
double score = 2 [(google.api.field_behavior) = REQUIRED];
BoundingBox bounding_box = 3 [(google.api.field_behavior) = REQUIRED];
}
repeated Detection detections = 1;
}

// Segmentation
message SegmentationResult {
message Segment {
string class = 1 [(google.api.field_behavior) = REQUIRED];
double score = 2 [(google.api.field_behavior) = REQUIRED];
ImageMask image_mask = 3;
BoundingBox bounding_box = 4;
}
repeated Segment segments = 1;
}

message NamedEntityResult {
message NamedEntity {
string entity_group = 1 [(google.api.field_behavior) = REQUIRED];
double score = 2 [(google.api.field_behavior) = REQUIRED];
TextSpan text_span = 3;
}
repeated NamedEntity entities = 1;
}

// Text summarization
// Text generation
// Translation
message TextResult {
string text = 1;
}

// Image/video
message ImageResult {
repeated bytes data = 1;
}

// Audio segmentation
// Time-series classification
// Regression
// Ranking
```

## Explanations

```proto
syntax = "proto3";
package chassis.v2;

import "chassis/v2/types.proto";

message ImageExplanation {
ImageMask mask = 1;
}

message TextExplanation {
message TextSpanScore {
TextSpan text_span = 1;
double score = 2;
}
message ClassResults {
string class = 1;
repeated TextSpanScore scores = 2;
}
repeated ClassResults class_results = 1;
}

// Saliency maps
// SHAP
// Lime's tabular
// Lime text classification
// Object detection
```

## Appendix B: Example Implementations
